{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IT18113600\n",
    "# Perera G.Y.N\n",
    "\n",
    "# Q1)\n",
    "# a)\n",
    "\n",
    "import os\n",
    "\n",
    "# -----------------LIST APPROACH----------------------\n",
    "# def termsAsList() :\n",
    "    \n",
    "#     termList = []\n",
    "#     os.chdir('F:\\\\SLIIT\\Year 3\\\\Semester 2\\\\IRWA\\\\Assignment\\\\assignment\\\\docs')\n",
    "\n",
    "#     #assign the files to a list\n",
    "#     fileList = os.listdir(os.getcwd())\n",
    "   \n",
    "#     for file in fileList :\n",
    "#         with open(file, 'r') as f:\n",
    "            \n",
    "#             #get the sentences in the documents, convert them to the lower case and split\n",
    "#             words = f.read().lower().split()\n",
    "#             print(\"hello\")\n",
    "#             for word in words :\n",
    "#                 #tokenize, remove unnessesary commas and others(special symbols)\n",
    "#                 if word[-1] in [',','!','?','.']:\n",
    "#                     word = word[:-1]\n",
    "#                     print(word)\n",
    "#                 #if the word not in the dictionary keys, new key is created \n",
    "#                 if word not in termList :\n",
    "#                     termList.append(word)\n",
    "#     return termList\n",
    "\n",
    "# print(termsAsList())\n",
    "  \n",
    "#--------------------DICTOINARY APPROACH----------------------------------   \n",
    "documentList = ['D1.txt', 'D2.txt', 'D3.txt'] \n",
    "\n",
    "def identifyTerms() :\n",
    "    #dictionary initializing\n",
    "    termDictionary = {}\n",
    "\n",
    "    #get the path of the related documents directory\n",
    "    os.chdir('F:\\\\SLIIT\\Year 3\\\\Semester 2\\\\IRWA\\\\Assignment\\\\assignment\\\\docs')\n",
    "\n",
    "    #assign the files to a list\n",
    "    fileList = os.listdir(os.getcwd())\n",
    "    for file in fileList :\n",
    "        with open(file, 'r') as f:\n",
    "            \n",
    "            #get the sentences in the documents, convert them to the lower case and split\n",
    "            words = f.read().lower().split()\n",
    "            for word in words :\n",
    "                #tokenize, remove unnessesary commas and others(special symbols)\n",
    "                if word[-1] in [',','!','?','.']:\n",
    "                    word = word[:-1]\n",
    "                    print(word)\n",
    "                #if the word not in the dictionary keys, new key is created \n",
    "                if word not in termDictionary.keys() :\n",
    "                    termDictionary[word] = [f.name]\n",
    "                #if the word is already exists in the dictionary, then the relavent document name\n",
    "                # will be added to the value list of that key   \n",
    "                else :\n",
    "                    if file not in termDictionary[word]:\n",
    "                        termDictionary[word] += [f.name]\n",
    "\n",
    "    return termDictionary\n",
    "\n",
    "identifyTerms()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b)\n",
    "\n",
    "incidentDic = {}\n",
    "#get the inverted index dictionary\n",
    "incidentDic = identifyTerms()\n",
    "# incidentMatrix = []\n",
    "incidentMatrix = {}\n",
    "\n",
    "for i in incidentDic.keys() :\n",
    "    internalList = []\n",
    "    \n",
    "    #if the document exists as a dictionary value of a particualr key,\n",
    "    #then incident matrix value will be updates as 1, if not 0\n",
    "    for document in documentList:\n",
    "        if document in incidentDic[i]:\n",
    "            internalList.append(1)\n",
    "        else:\n",
    "            internalList.append(0)\n",
    "    # if 'D1.txt' in incidentDic[i]:\n",
    "    #     internalList.append(1)\n",
    "    # else:\n",
    "    #     internalList.append(0)\n",
    "\n",
    "    # if 'D2.txt' in incidentDic[i]:\n",
    "    #     internalList.append(1)\n",
    "    # else:\n",
    "    #     internalList.append(0)\n",
    "\n",
    "    # if 'D3.txt' in incidentDic[i]:\n",
    "    #     internalList.append(1)\n",
    "    # else:\n",
    "    #     internalList.append(0)\n",
    "\n",
    "    if i not in incidentMatrix.keys():\n",
    "        incidentMatrix[i] = internalList\n",
    "#     incidentMatrix.append(internalList)\n",
    "\n",
    "#print the Column headers\n",
    "print(\"{}\\t\\t{}\".format(\"Terms\", ['D1', 'D2', 'D3']))\n",
    "\n",
    "#print rows\n",
    "for i, j in incidentMatrix.items():\n",
    "    print(\"{}\\t\\t{}\".format(i, j))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToFile(dictionary, path):\n",
    "    os.chdir(path)\n",
    "    with open('index-file.txt', 'w') as indexFile:\n",
    "        \n",
    "        for word, files in dictionary.items():\n",
    "            indexFile.write(word + \" \")\n",
    "\n",
    "            for file in files:\n",
    "                indexFile.write(file[:file.find(\".txt\")] + \" \")\n",
    "            \n",
    "            indexFile.write(f'{len(files)}\\n')\n",
    "\n",
    "writeToFile(identifyTerms(), 'F:\\\\SLIIT\\Year 3\\\\Semester 2\\\\IRWA\\\\Assignment\\\\assignment\\\\writes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c)\n",
    "\n",
    "resultSet = identifyTerms()\n",
    "# intialize three lists to store the documents related to the keys\n",
    "listFrodo = []\n",
    "listOrc = []\n",
    "listSword = []\n",
    "listSam = []\n",
    "listBlue = []\n",
    "\n",
    "# go through the inverted matrix and identify the specific keys\n",
    "for key in resultSet :\n",
    "    if key == \"frodo\":\n",
    "        listFrodo = resultSet[key]\n",
    "    elif key == \"orc\":\n",
    "        listOrc = resultSet[key]\n",
    "    elif key == \"sword\":\n",
    "        listSword = resultSet[key]\n",
    "    elif key == \"sam\":\n",
    "        listSam = resultSet[key]\n",
    "    elif key == \"blue\":\n",
    "        listBlue = resultSet[key]\n",
    "    \n",
    "print(listFrodo)\n",
    "print(listOrc)\n",
    "print(listSword)\n",
    "print(listSam)\n",
    "print(listBlue)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logical Operators for future use\n",
    "# AND operation for three parameters\n",
    "def AND_op(postingList1, postingList2, postingList3) :                \n",
    "    return set(postingList1).intersection(postingList2).intersection(postingList3)\n",
    "# AND operation for two parameters\n",
    "def AND_op2(postingList1, postingList2) :                \n",
    "    return set(postingList1).intersection(postingList2)\n",
    "# NOT operation for two parameters\n",
    "def NOT_op(listParam, notVariable) :\n",
    "    notList = []\n",
    "    for i in notVariable :\n",
    "        if i not in listParam:\n",
    "            notList.append(i)\n",
    "    # print(\"Not List {}\".format(notList))\n",
    "    return notList\n",
    "\n",
    "# TODO: Check this again to identify how the symmetric difference works \n",
    "    # return set(listParam).symmetric_difference(notVariable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c)\n",
    "# q1)\n",
    "\n",
    "#Frodo AND orc AND sword\n",
    "print(\"Answer for Frodo AND orc AND sward: {}\".format(AND_op(listFrodo, listOrc, listSword)))\n",
    "\n",
    "# q2)\n",
    "\n",
    "#Sam AND blue\n",
    "sam_and_blue = AND_op2(listSam, listBlue)\n",
    "\n",
    "#NOT Frodo\n",
    "not_frodo = NOT_op(listFrodo, sam_and_blue)\n",
    "\n",
    "# Sam AND blue AND NOT Frodo\n",
    "output = AND_op2(sam_and_blue, not_frodo)\n",
    "\n",
    "\n",
    "print(\"Answer for Sam AND blue AND NOT Frodo: {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2)\n",
    "\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1) / 4)\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "# def getTokenizedList(file):\n",
    "#     tokenList = []\n",
    "#     invertedIndex = {}\n",
    "# #     for file in fileList2 :\n",
    "# #         with open(file, 'r') as f:\n",
    "\n",
    "# #             #get the sentences in the documents, convert them to the lower case and split\n",
    "# #             words = f.read().split()\n",
    "#     #split file to sentences\n",
    "#     sentences = file.split(\".\")\n",
    "\n",
    "#     for sentence in sentences :\n",
    "#             #retreive words from sentences\n",
    "#             words = sentence.split()\n",
    "#             for word in words :\n",
    "#                 if word[-1] in [',','!','?','.']:\n",
    "#                         word = word[:-1]\n",
    "#         #                     print(word)\n",
    "\n",
    "#                 if word not in tokenList :\n",
    "#                     tokenList.append(word)\n",
    "\n",
    "#                 if word not in invertedIndex.keys():\n",
    "#                     invertedIndex[word] = file.name\n",
    "#                 else :\n",
    "#                     if file not in invertedIndex[word]:\n",
    "#                         invertedIndex[word] += file.name\n",
    "#     return tokenList, invertedIndex\n",
    "    # print(tokenList)\n",
    "# getTokenizedList('C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\reuters\\\\training')\n",
    "\n",
    "os.chdir('C:/Users/User/AppData/Roaming/nltk_data/corpora/reuters/training')\n",
    "#assign the files to a list\n",
    "fileList2 = os.listdir(os.getcwd())\n",
    "print(len(fileList2))\n",
    "tokenList = []\n",
    "invertedIndex = {}\n",
    "\n",
    "for file in fileList2 :\n",
    "    with open(file, 'r') as f:\n",
    "        # for w in getTokenizedList(f.read())[0]:\n",
    "        #     retrievedList.append(w)\n",
    "\n",
    "        #split file to sentences\n",
    "        sentences = nltk.sent_tokenize(f.read().lower())\n",
    "\n",
    "        for sentence in sentences :\n",
    "                #retreive words from sentences\n",
    "                words = nltk.word_tokenize(sentence)\n",
    "                for word in words :\n",
    "                    if word not in tokenList :\n",
    "                        tokenList.append(word)\n",
    "\n",
    "                    if word not in invertedIndex.keys():\n",
    "                        invertedIndex[word] = [file]\n",
    "                    else :\n",
    "                        if file not in invertedIndex[word]:\n",
    "                            invertedIndex[word] += [file]\n",
    "# print(invertedIndex)\n",
    "\n",
    "# for file in fileList2 :\n",
    "#     with open(file, 'r') as f:\n",
    "#         # for w in getTokenizedList(f.read())[0]:\n",
    "#         #     retrievedList.append(w)\n",
    "\n",
    "#     #     for file in fileList2 :\n",
    "#     #         with open(file, 'r') as f:\n",
    "\n",
    "#     #             #get the sentences in the documents, convert them to the lower case and split\n",
    "#     #             words = f.read().split()\n",
    "#         #split file to sentences\n",
    "#         sentences = f.read().lower().split(\".\")\n",
    "\n",
    "#         for sentence in sentences :\n",
    "#                 #retreive words from sentences\n",
    "#                 words = sentence.split()\n",
    "#                 for word in words :\n",
    "#                     if word[-1] in [',','!','?','.']:\n",
    "#                             word = word[:-1]\n",
    "#                             # print(word)\n",
    "#                     # word = nltk.word_tokenize(word)\n",
    "#                     if word not in tokenList :\n",
    "#                         tokenList.append(word)\n",
    "\n",
    "#                     if word not in invertedIndex.keys():\n",
    "#                         invertedIndex[word] = [file]\n",
    "#                     else :\n",
    "#                         if file not in invertedIndex[word]:\n",
    "#                             invertedIndex[word] += [file]\n",
    "\n",
    "print(invertedIndex)\n",
    "def getPostingList(index):\n",
    "    return invertedIndex[index]\n",
    "\n",
    "print(getPostingList('bahia'))\n",
    "# print(invertedIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(tokenList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2)\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stemming(tokenList) :\n",
    "    \n",
    "    stemmedList = []\n",
    "    \n",
    "    for word in tokenList:\n",
    "        stemmedList.append(ps.stem(word))\n",
    "    \n",
    "    return stemmedList\n",
    "\n",
    "stemmedWordList = stemming(tokenList)\n",
    "# print(len(tokenList))\n",
    "# print(len(stemmedWordList))\n",
    "\n",
    "stemmedFinalList = []\n",
    "\n",
    "# TODO: Recheck this\n",
    "\n",
    "# Remove duplicates\n",
    "for word in stemmedWordList:\n",
    "    if word not in stemmedFinalList:\n",
    "        stemmedFinalList.append(word)\n",
    "    # if word in stemmedFinalList:\n",
    "    #     print(word)\n",
    "\n",
    "print(stemmedFinalList)\n",
    "# print(stemmedWordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5)\n",
    "def addPostingList(key, value):\n",
    "    if key not in invertedIndex.keys:\n",
    "        invertedIndex[key] = value\n",
    "    else:\n",
    "        if value is not in invertedIndex[key]:\n",
    "            invertedIndex[key] += value\n",
    "    \n",
    "    return invertedIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invertedIndex = {}\n",
    " os.chdir('C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\reuters\\\\training')\n",
    "#assign the files to a list\n",
    "fileList2 = os.listdir(os.getcwd())\n",
    "print(len(fileList2))\n",
    "retrievedList = []\n",
    "for file in fileList2 :\n",
    "    with open(file, 'r') as f:\n",
    "        for w in getTokenizedList(f.read()):\n",
    "            retrievedList.append(w)\n",
    "        \n",
    "print(retrievedList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Q3)\n",
    "# 1)\n",
    "\n",
    "word = 'hello'\n",
    "permutermWord = word + '$'\n",
    "changedWordList = []\n",
    "\n",
    "# Run the loop for number of characters(including #)\n",
    "for w in range(0, len(permutermWord)):\n",
    "    changingWord = ''\n",
    "    # Get the each character and add it to a separate string,\n",
    "    # here it will increment the starting index according to the w value\n",
    "    for i in range(w, len(permutermWord)):\n",
    "        changingWord += permutermWord[i]\n",
    "     \n",
    "    if len(changingWord) < len(permutermWord):\n",
    "        for j in range(0, len(permutermWord) - len(changingWord)):\n",
    "            changingWord += permutermWord[j]    \n",
    "    print(changingWord)\n",
    "    changedWordList.append(changingWord)\n",
    "\n",
    "# added the words to a list for future use\n",
    "#  print(changedWordList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2)\n",
    "def levenshtein_distance(word1, word2):\n",
    "    #compare the length of the words and get the difference,\n",
    "    #that difference will be initiated that distanca value\n",
    "    if len(word1)> len(word2):\n",
    "        difference = len(word1) - len(word2)\n",
    "        word1 = word1[:len(word2)]\n",
    "    elif len(word2)> len(word1):\n",
    "        difference = len(word2) - len(word1)\n",
    "        word2 = word2[:len(word1)]\n",
    "    else:\n",
    "        difference = 0\n",
    "\n",
    "    #if the letters are not matched, then the difference will be increased by 1\n",
    "    for character in range(len(word1)):\n",
    "        if word1[character] != word2[character]:\n",
    "            difference += 1\n",
    "\n",
    "    return difference\n",
    "\n",
    "print(\"Edit Distance(Levenshtein) Between two words: \" + str(levenshtein_distance('cat', 'dogs')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3)\n",
    "\n",
    "soundexDic = {'AEIOUHWY': ['A', 'E', 'I', 'O', 'U', 'H', 'W', 'Y'], \n",
    "                'BFPV' : ['B', 'F', 'P', 'V'],\n",
    "                'CGJKQSXZ': ['C', 'G', 'J', 'K', 'Q', 'S', 'X', 'Z'],\n",
    "                'DT': ['D', 'T'],\n",
    "                'L': ['L'],\n",
    "                'MN': ['M', 'N'],\n",
    "                'R': ['R'] }\n",
    "\n",
    "def soundex(word):\n",
    "    letters = [i for i in word.upper()]\n",
    "    \n",
    "    soundex_string = letters[0]\n",
    "    characterVal = 0\n",
    "    # print(soundex_string)\n",
    "    for w in letters[1:]:\n",
    "        if w in soundexDic['AEIOUHWY']:\n",
    "            soundex_string = soundex_string + str(0)\n",
    "        elif w in soundexDic['BFPV']:\n",
    "            soundex_string = soundex_string + str(1)\n",
    "        elif w in soundexDic['CGJKQSXZ']:\n",
    "            soundex_string = soundex_string + str(2)\n",
    "        elif w in soundexDic['DT']:\n",
    "            soundex_string = soundex_string + str(3)\n",
    "        elif w in soundexDic['L']:\n",
    "            soundex_string = soundex_string + str(4)\n",
    "        elif w in soundexDic['MN']:\n",
    "            soundex_string = soundex_string + str(5)\n",
    "        elif w in soundexDic['R']:\n",
    "            soundex_string = soundex_string + str(6)    \n",
    "\n",
    "        # for key in soundexDic.keys():\n",
    "        #     if w in soundexDic[key]:\n",
    "        #         soundex_string = soundex_string + str(int(characterVal))\n",
    "        #         characterVal += 1\n",
    "\n",
    "    soundex_final = soundex_string[0]\n",
    "\n",
    "    # get the values from the second character(index wise 1st)\n",
    "    for w in soundex_string[1:]:\n",
    "       \n",
    "        # TODO: Remove second consecative charatcter\n",
    "        # if w <= len(soundex_string) - 2:\n",
    "        # here it checks wether the last added value to the string is equal to this value\n",
    "        # if it is equal, it will not be added.\n",
    "        # Rule: Cannot have pair of consecutive digits\n",
    "        if w != soundex_final[-1]:\n",
    "            soundex_final = soundex_final + w\n",
    "   \n",
    "    \n",
    "    soundex_final = soundex_final.replace('0', '')\n",
    "\n",
    "    # if the character count is less than 4, then we need to fill the remaining spaces with 0\n",
    "    # ex: H65 --> H650\n",
    "    if len(soundex_final) < 4 :\n",
    "        for i in range(0, 4 - len(soundex_final)):\n",
    "            soundex_final = soundex_final + str(0)\n",
    "    \n",
    "    # when the character count is greater than 4, we take only the first 4 characters\n",
    "    elif len(soundex_final) > 4 :\n",
    "        soundex_final = soundex_final[:4]\n",
    "\n",
    "    return soundex_final\n",
    "\n",
    "print(\"Soundex Output: {}\".format(soundex('herman')))\n",
    "print(\"Soundex Output: {}\".format(soundex('hermann')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}